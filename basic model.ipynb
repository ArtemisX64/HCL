{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f7a6d0a-912d-451d-974e-28842e1b0e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "nlp = spacy.blank(\"en\")  # Create a blank English model\n",
    "ner = nlp.add_pipe(\"ner\")  # Add NER pipeline\n",
    "\n",
    "# Define training data (sample)\n",
    "TRAIN_DATA = [\n",
    "    (\"Apple is looking at buying U.K. startup for $1 billion\", \n",
    "     {\"entities\": [(0, 5, \"ORG\"), (27, 31, \"LOC\"), (44, 54, \"MONEY\")]}),\n",
    "\n",
    "    (\"Elon Musk founded SpaceX\", \n",
    "     {\"entities\": [(0, 9, \"PERSON\"), (18, 24, \"ORG\")]}),\n",
    "\n",
    "    (\"Tesla is opening a new plant in Texas\", \n",
    "     {\"entities\": [(0, 5, \"ORG\"), (34, 39, \"LOC\")]}),  # Added Texas as GPE\n",
    "\n",
    "    (\"Amazon's headquarters is in Seattle\", \n",
    "     {\"entities\": [(0, 6, \"ORG\"), (27, 34, \"LOC\")]}),\n",
    "\n",
    "    (\"Google is based in California\", \n",
    "     {\"entities\": [(0, 6, \"ORG\"), (17, 27, \"LOC\")]}),\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "# Add labels to the model\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations[\"entities\"]:\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "# Convert data into spaCy format\n",
    "db = DocBin()\n",
    "for text, annotations in TRAIN_DATA:\n",
    "    doc = nlp.make_doc(text)\n",
    "    ents = [doc.char_span(start, end, label) for start, end, label in annotations[\"entities\"]]\n",
    "    doc.ents = [ent for ent in ents if ent is not None]\n",
    "    db.add(doc)\n",
    "\n",
    "db.to_disk(\"./train.spacy\")  # Save the formatted training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e55c5577-92e7-49aa-b4e4-5af207538c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"File exists:\", os.path.exists(\"./train.spacy\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "255b1d9f-032a-429b-8157-402882c873c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Apple', 'ORG'), ('U.K.', 'LOC'), ('$1 billion', 'MONEY')]\n",
      "[('Elon Musk', 'PERSON'), ('SpaceX', 'ORG')]\n",
      "[('Tesla', 'ORG')]\n",
      "[('Amazon', 'ORG')]\n",
      "[('Google', 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "db = DocBin().from_disk(\"./train.spacy\")\n",
    "docs = list(db.get_docs(nlp.vocab))\n",
    "\n",
    "for doc in docs:\n",
    "    print([(ent.text, ent.label_) for ent in doc.ents])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1995496c-ff45-4422-a772-200b7d675154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/home/kavi/anaconda3/lib/python3.12/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Google is based in California\" with entities \"[(0, 6, 'ORG'), (17, 27, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/var/home/kavi/anaconda3/lib/python3.12/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Amazon's headquarters is in Seattle\" with entities \"[(0, 6, 'ORG'), (27, 34, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/var/home/kavi/anaconda3/lib/python3.12/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Tesla is opening a new plant in Texas\" with entities \"[(0, 5, 'ORG'), (34, 39, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: {'ner': 27.67866127938032}\n",
      "Epoch 2, Loss: {'ner': 20.772579601034522}\n",
      "Epoch 3, Loss: {'ner': 10.623432686115848}\n",
      "Epoch 4, Loss: {'ner': 10.884079404712537}\n",
      "Epoch 5, Loss: {'ner': 7.701406372836451}\n",
      "Epoch 6, Loss: {'ner': 5.871904224225555}\n",
      "Epoch 7, Loss: {'ner': 4.1351512459421285}\n",
      "Epoch 8, Loss: {'ner': 2.024194936417084}\n",
      "Epoch 9, Loss: {'ner': 1.2571193380157102}\n",
      "Epoch 10, Loss: {'ner': 0.2827654943323666}\n",
      "Epoch 11, Loss: {'ner': 0.007764039087490088}\n",
      "Epoch 12, Loss: {'ner': 0.003119634221266556}\n",
      "Epoch 13, Loss: {'ner': 5.925263782684832e-05}\n",
      "Epoch 14, Loss: {'ner': 6.018586171279166e-06}\n",
      "Epoch 15, Loss: {'ner': 3.2223673323862414e-06}\n",
      "Epoch 16, Loss: {'ner': 6.277056919783784e-07}\n",
      "Epoch 17, Loss: {'ner': 4.1590309486718154e-07}\n",
      "Epoch 18, Loss: {'ner': 6.857662104340117e-07}\n",
      "Epoch 19, Loss: {'ner': 2.1894220469427437e-07}\n",
      "Epoch 20, Loss: {'ner': 1.4637296083601193e-06}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "nlp.begin_training()\n",
    "for epoch in range(20):  # Adjust epochs as needed\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}\n",
    "    for text, annotations in TRAIN_DATA:\n",
    "        doc = nlp.make_doc(text)\n",
    "        example = Example.from_dict(doc, annotations)\n",
    "        nlp.update([example], losses=losses)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {losses}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f77e9df-9a58-40ca-a4b9-9f688b1cbd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon Musk PERSON\n",
      "Redmi ORG\n",
      "India GPE\n",
      "2026 DATE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # Pre-trained model\n",
    "doc = nlp(\"Elon Musk is buying a Redmi showroom in India by 2026\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "821f570b-68a9-4c79-a75a-a0c427a9bc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla ORG\n",
      "U.K. GPE\n",
      "Steve Jobs PERSON\n",
      "$1 billion MONEY\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # Pre-trained model\n",
    "doc = nlp(\"Tesla is looking at buying U.K. startup by Steve Jobs for $1 billion\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d9738a-1dde-456a-9200-34b7e641700c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
